---
title: "Desarrollo de modelo de regresión lineal simple"
subtitle: "Ejemplo de aplicación en Python y R"
format: 
  html:
    number-sections: true
    toc: true
    embed-resources: true
    crossrefs-hover: false
    lang: es
    bibliography: bibliografia/bibliografia.bib
    csl: bibliografia/ieee.csl
date: last-modified
author:
  - name: Víctor Gauto
    corresponding: true
    email: victor.gauto@ca.frre.utn.edu.ar
    affiliations:
      - name: GISTAQ (UTN-FRRe)
        url: https://www.instagram.com/gistaq.utn/
abstract: |
  Este sitio web contiene cuestiones etc
keywords:
  - GISTAQ
  - UTN
  - FRRe
  - Quarto
jupyter: python3
knitr: true
---

<!-- Instalo los paquetes de Python en un *environment* (`sklearn-env`). -->

```{r}
#| eval: false
#| echo: false

reticulate::conda_create(
  envname = "sklearn-env",
  packages = c("scikit-learn", "matplotlib")
)
```


```{r}
#| echo: false
#| warning: false

library(reticulate)
reticulate::use_python(
  "C:\\Users\\victo\\anaconda3\\envs\\sklearn-env/python.exe"
)
```

Diferentes metodologías para la resolución de una regresión simple por el método de mínimos cuadrados.

## **Python**, con `sklearn`

Se muestra a continuación el tutorial mostrado en para el modelo [Mínimos cuadrados ordinarios](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#ordinary-least-squares-example).

Importo la librería `sklearn`, funciones de interés y para generar figuras.

```{python}
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
```

Cargo los datos de interés y divido en entrenamiento y validación.

```{python}
X, y = load_diabetes(return_X_y=True)
X = X[:, [2]]  # Use only one feature
X_train, X_test, y_train, y_test = train_test_split(
  X, y, test_size=20, shuffle=False
)
```

Creo un modelo de regresión y ajusto utilizando los datos de entrenamiento.

```{python}
regressor = LinearRegression().fit(X_train, y_train)
```

Evalúo el modelo generado a partir de las **métricas de desempeño**.

```{python}
y_pred = regressor.predict(X_test)
p_rmse = mean_squared_error(y_test, y_pred)
p_r2 = r2_score(y_test, y_pred)
```

::: {.callout-note icon="false" title="Métricas de desempeño"}

El error cuadrático medio es: `{r} round(py$p_rmse, 3)`.

El coeficiente de determinación (R<sup>2</sup>) es: `{r} round(py$p_r2, 3)`.

:::

Visualizo los resultados comparando el conjunto de entrenamiento y validación.

::: {.column-body-outset}

```{python}
fig, ax = plt.subplots(ncols=2, figsize=(10, 5), sharex=True, sharey=True)

ax[0].plot(
    X_train,
    regressor.predict(X_train),
    linewidth=3,
    color="#17A77E",
    label="Modelo",
)
ax[0].scatter(X_train, y_train, label="Entrenamiento", color = "#9D50A6", alpha = .6)
ax[0].set(xlabel="Característica", ylabel="Objetivo", title="Conjunto de entrenamiento")
ax[0].legend()

ax[1].plot(X_test, y_pred, linewidth=3, color="#17A77E", label="Modelo")
ax[1].scatter(X_test, y_test, label="Validación", color = "#9D50A6", alpha = .6)
ax[1].set(xlabel="Característica", ylabel="Objetivo", title="Conjunto de validación")
ax[1].legend()

fig.suptitle("Regresión lineal")

plt.show()
```

:::

## **R**, con `tidymodels`

Cargo los paquetes para el procesamiento de datos y desarrollo del modelo.

```{r}
#| warning: false
library(tidyverse)
library(tidymodels)
```

Divido el conjunto de datos en entrenamiento y validación.

```{r}
penguins <- palmerpenguins::penguins

set.seed(2025)
penguins_split <- initial_split(penguins, strata = body_mass_g)
penguins_train <- training(penguins_split)
penguins_test  <- testing(penguins_split)
```

Creo un modelo lineal y una *receta* que relacione las variables de interés.

```{r}
lm_model <- linear_reg() |> 
  set_engine("lm")

lm_recipe <- recipe(body_mass_g ~ bill_length_mm, data = penguins_train)
```

Combino el modelo con la receta en un *workflow* y ajusto con los datos de entrenamiento.

```{r}
lm_wflow <- workflow(
  preprocessor = lm_recipe,
  spec = lm_model
)

lm_fit <- fit(lm_wflow, penguins_train)
```

Genero estimaciones a partir de los datos de validación con el modelo obtenido.

```{r}
penguins_test_res <- predict(
  lm_fit, new_data = select(penguins_test, -body_mass_g)
) |> 
  bind_cols(select(penguins_test, body_mass_g))
```

Las métricas de desempeño resultan:

```{r}
r_rmse <- yardstick::rmse(penguins_test_res, truth = body_mass_g, estimate = .pred)
r_r2 <- yardstick::rsq(penguins_test_res, truth = body_mass_g, estimate = .pred)
```

::: {.callout-note icon="false" title="Métricas de desempeño"}

El error cuadrático medio (RMSE): `{r} round(r_rmse$.estimate, 3)`.

El coeficiente de determinación (R<sup>2</sup>): `{r} round(r_r2$.estimate, 3)`.

:::

Comparo las estimaciones dadas por el modelo con los valores reales.

```{r}
ggplot(penguins_test_res, aes(body_mass_g, .pred)) +
  geom_smooth(se = FALSE, method = "lm", formula = y ~ x, color = "#17A77E") +
  geom_point(color = "#9D50A6", alpha = .6) +
  labs(x = "Valor medido", y = "Valor estimado") +
  theme_bw() +
  theme(
    aspect.ratio = 1
  )
```

Más recursos:

* [Tutoriales](https://www.tidymodels.org/start/) de `{tidymodels}`.

* [Tidy Modeling with R](https://www.tmwr.org/).


